# Logistics Indicators API

## üóíÔ∏è Descri√ß√£o
O projeto trata-se de uma API que permite o cadastro de clientes e atendimentos a partir da carga com arquivo .csv ou cadastro individual para compor uma base de dados logistica, e a partir das informa√ß√µes a gera√ß√£o de relat√≥rios de indicadores de produtividade e SLA dos atendimentos dos t√©cnicos log√≠sticos (Green Angels).

## üéØ Objetivos
- Cadastro, consulta, filtro, atualiza√ß√£o e dele√ß√£o de clientes (customers)
- Cadastro, consulta, filtro e atualiza√ß√£o de atendimentos (customer_services)
- Carga de clientes e atendimentos a partir de arquivo .csv
- Consulta de indicadores de opera√ß√£o:
  - Produtividade por Green Angel
  - SLA de cada base log√≠stica
  - SLA de cada Green Angel

## ‚ö° Principais Features

- Autentica√ß√£o JWT com rotas de registro, login e refresh token
- [Script de gera√ß√£o de dados fict√≠cios de clientes](https://github.com/jocsakesley/logistics_indicators_api/blob/main/utils/create_customers.py) a partir dos valores √∫nicos da coluna `id_cliente` do arquivo de atendimentos
- Carga do arquivo de clientes e atendimentos a partir de uma rota http que faz o processamento ass√≠ncrono, com transforma√ß√£o dos dados de `data_de_atendimento` que estavam despadronizadaos, utilizando uma thread para recep√ß√£o do arquivo e envio das linhas para uma fila, evitando bloqueio da requisi√ß√£o, e 100 threads para a leitura da fila e grava√ß√£o no banco de dados em chunks de 2000 registros por vez. As threads, chunks e sleep times s√£o configur√°veis por vari√°veis de ambiente garantindo o melhor tradeoff para produ√ß√£o (O tempo de processamento atual no endere√ßo p√∫blico est√° maior que ao rodar localmente, devido a limita√ß√£o de configura√ß√£o para evitar custos)
- Consulta do total de registros para clientes e atendimentos nas rotas `/v1/customers/total` e `/v1/services/total`, facilitando o monitoramento da conclus√£o da carga batch.
- Consulta da rota `/v1/customers` com filtros para todos os campos (`email`, `nome` e `telefone`) e pagina√ß√£o a partir dos parameters `limit` e `offset`
- Consulta da rota `/v1/services` com filtros para todos os campos (`angel`, `id_cliente`, `data_de_atendimento`, `data_limite` e `polo`) e pagina√ß√£o a partir dos parameters `limit` e `offset`
- Consuta da rota `/v1/indicators/productivity`, `/v1/indicators/sla/angel` e `/v1/indicators/sla/polo` com filtros de data (`start_date=YYYY-MM-DD` e `end_date=YYYY-MM-DD`) e ordena√ß√£o (`sort_field=<total, total_sla, avg_time>`  e `desc=<true, false>`)
- Monitoramento das requisi√ß√µes atrav√©s de logs com status e tempo de resposta, implementado a partir de um midlleware que calcula os tempos a cada requisi√ß√£o
![image](https://github.com/user-attachments/assets/769979f7-85a0-4cb2-a918-fa6b7542945b)
- Monitoramento do tempo de carga do arquivo batch atrav√©s dos logs com uma m√©dia de 48 segundos para o arquivo de clientes com 573670 linhas e 80 segundos para o arquivo de atendimentos com 1048575 linhas
![image](https://github.com/user-attachments/assets/4e00b4d9-4a1f-4b4b-abb5-7ad0e0cf1751)
![image](https://github.com/user-attachments/assets/dc685b2a-2494-4c89-9aa4-c3bfd6b8dea9)
- Monitoramento atrav√©s de requests √†s rotas `/v1/metrics` com m√©tricas de CPU, mem√≥ria e disco e `/v1/health` para monitoramento da sa√∫de do servidor
- Testes unit√°rios para os usecases que cont√©m o core das regras de neg√≥cios
- Testes end-to-end foram feitos a partir de uma collection do postman, por√©m podem ser adicionados ao projeto
- Padroniza√ß√£o de commits para cada tipo de altera√ß√£o (feat, refactor, test, build, doc) 
- Execu√ß√£o do projeto a partir do docker compose
- Build e push da imagem para o docker hub atrav√©s da pipeline do github actions
- Deploy da aplica√ß√£o na AWS ECS a partir da pipeline do CloudFormation (optei por esse cloud provider por mais familiariade)
- Aplica√ß√£o desenvolvida seguindo princ√≠pios da orienta√ß√£o a objetos utilizando uma metodologia baseada na Clean Archtecture onde foram separadas as camadas de infra, controllers e usecases seguindo o seguinte fluxo:
  ![image](https://github.com/user-attachments/assets/b01a460a-7b7a-4bd3-84f9-9bdfbf5807e0)

  
## üîß Pr√© requisitos t√©cnicos
- Containers Docker para a execu√ß√£o da API e do banco de dados.
- Python 3 com Flask para cria√ß√£o da API
- Banco de dados Postgresql
- Projeto entregue pelo github
- README com instru√ß√µes para instala√ß√£o e execu√ß√£o do projeto

## üöÄ Instala√ß√£o e Setup
Para a execu√ß√£o local do projeto √© necess√°rio que o [docker](https://docs.docker.com/engine/install/) e o [docker compose](https://docs.docker.com/compose/install/) estejam instalados e seguidos os seguintes passos:

1. Clone o reposit√≥rio
```bash
git clone https://github.com/jocsakesley/logistics_indicators_api.git
cd logistics_indicators_api
```

2. Configure as vari√°veis de ambiente (opcional)

Arquivo .env disponibilizado no reposit√≥rio apenas para desenvolvimento.
Para produ√ß√£o √© recomendado que as vari√°veis sens√≠veis sejam setadas de forma segura atrav√©s de um gerenciador de segredos.

Vari√°veis do arquivo .env:
 ```
 #Database
 POSTGRES_PASSWORD=postgres
 POSTGRES_USER=jocsa
 POSTGRES_DB=logistics
 POSTGRES_HOST=db
 
 #Autentica√ß√£o
 JWT_SECRET_KEY=my-secret
 
 #File handler
 NUMBER_WORKER_FILE_THREADS=100
 SECONDS_WAIT_QUEUE_EMPTY=10
 SIZE_FILE_CHUNKS=2000
```
3. Inicialize o docker (pelo docker desktop ou pelo teminal)
   
4. Rode o docker-compose
```bash
docker-compose up --build -d
```
Obs.: Usar o comando sem o -d para acompanhar os logs no terminal

5. Verifique que os containers da aplica√ß√£o, db est√£o rodando
```bash
docker ps
```
6. Acesse a API pela url `localhost:8000` mais a rota de prefer√™ncia segundo a documenta√ß√£o

## üìì Documenta√ß√£o da API

A documenta√ß√£o pode ser baixada a partir [desse link](https://github.com/jocsakesley/logistics_indicators_api/blob/main/docs/logistics-api.postman_collection.json)  e importada para um client http como o postman ou baixar a [especifica√ß√£o openapi nesse link](https://github.com/jocsakesley/logistics_indicators_api/blob/main/docs/openapi.yaml) e importar no editor online [swagger editor](https://editor.swagger.io/) para uma melhor visualiza√ß√£o.

Obs.: Para as consultas, √© poss√≠vel remover os filtros para trazer todos os resultados, com pagina√ß√£o para clientes e atendimentos.

## üíª Como usar

- Registre um usu√°rio na rota `/v1/auth/register` com `username`, `email` e `password`
- Fa√ßa login na rota `/v1/auth/login` e copie o `access_token` retornado
- Em todas as chamadas passe no header o key `Authorization` e no value `Bearer <access_token>`
- Fa√ßa o upload do arquivo `customers_data.csv` na rota `/v1/customers/batch` 
- Monitore o total de linhas inseridas na rota `/v1/customers/total` (o total deve ser 573670)
- Fa√ßa o upload do arquivo `utils/bd_desafio.csv` na rota `/v1/services/batch`
- Monitore o total de linhas inseridas na rota `/v1/services/total` (o total deve ser 1048575) 
- Fa√ßa as devidas consultas conforme a documenta√ß√£o

## üß™ Rodando Testes
Os testes podem ser executados a partir dos seguintes comandos:

```bash
pip install -r tests/requirements_tests.txt
coverage run -m pytest -s -v tests
coverage report
```

## üî• Desafios
Durante a execu√ß√£o do projeto me deparei com alguns desafios para o deploy via pipeline do github actions. As roles de acesso para meu usu√°rio do github estavam funcionando por√©m o setup de configura√ß√£o da m√°quina remota requeria alguns passos que poderiam ser facilmente contornados com uma imagem da inst√¢ncia personalizada e consequentemente mais cara. Poderia fazer tamb√©m o provisionamento de infraestrutura via Terraform e github actions mas despriorizei devido ao tempo para a entrega e por ter uma alternativa para fazer o deploy.

Dessa forma optei por fazer o build e push da imagem pelo github actions no docker hub e a partir dessa imagem, com as configura√ß√µes de credenciais aws configuradas localmente, consegui fazer o deploy no ECS usando docker contex para criar o cluster e os services a partir do arquivo `docker-compose.prd.yml` do projeto que inicializa uma pipeline do CloudFormation com todos os recursos necess√°rios para disponibiliza√ß√£o p√∫blica do servi√ßo.

## üìù Oportunidades de melhoria
Para a evolu√ß√£o do projeto pude identificar alguns pontos de melhoria:
- Gerenciamento de usu√°rios (hoje s√≥ tem o registro)
- Revisar usecases que podem ser melhor divididos em outras partes de dominio de neg√≥cios
- Usar uma fila apartada da aplica√ß√£o via sdk para evitar perda de dados in memory em caso de falha do container da aplica√ß√£o
- Aumentar a cobertura de testes para todo o projeto
- Adicionar documenta√ß√£o do swagger na aplica√ß√£o de forma autom√°tica
- Corre√ß√£o para deploy inteiramente pelo github actions
- Provisionamento de infraestrutura via m√≥dulo Terraform na pipeline do github actions
- Criar uma distribution no CloudFront com a origin apontada para o endere√ßo do load balancer para minimizar a lat√™ncia das chamadas j√°  que o load balancer se encontra na regi√£o US North Virginia da AWS
- Registrar um dom√≠nio e criar um DNS no Route53 para acesso via nomes de dom√≠nio na URL 


## üë§ Autor
- Jocs√£ Kesley - Backend Developer
- Email - jocsadm@gmail.com
- Project Link: https://github.com/jocsakesley/logistics_indicators_api

## üìä Status do projeto
- Development

