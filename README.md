# Logistics Indicators API

## üóíÔ∏è Descri√ß√£o
O projeto trata-se de uma API que permite o cadastro de clientes e atendimentos a partir da carga com arquivo .csv ou cadastro individual para compor uma base de dados logistica, e a partir das informa√ß√µes a gera√ß√£o de relat√≥rios de indicadores de produtividade e SLA dos atendimentos dos t√©cnicos log√≠sticos (Green Angels).

## üéØ Objetivos
- Cadastro, consulta, filtro, atualiza√ß√£o e dele√ß√£o de clientes (customers)
- Cadastro, consutta, filtro e atualiza√ß√£o de atendimentos (customer_services)
- Carga de clientes e atendimentos a partir de arquivo .csv
- Consulta de indicadores de opera√ß√£o:
  - Produtividade por Green Angel
  - SLA de cada base log√≠stica
  - SLA de cada Green Angel

## ‚ö° Principais Features

- Autentica√ß√£o JWT com rotas de registro, login e refresh token
- [Script de gera√ß√£o de dados fict√≠cios de clientes](https://github.com/jocsakesley/logistics_indicators_api/blob/main/utils/create_customers.py) a partir dos valores √∫nicos da coluna `id_cliente` do arquivo de atendimentos
- Carga do arquivo de clientes e atendimentos a partir de uma rota http que faz o processamento ass√≠ncrono, com transforma√ß√£o dos dados de `data_de_atendimento` que estavam despadronizadaos, utilizando uma thread para recep√ß√£o do arquivo e envio das linhas para uma fila, evitando bloqueio da requisi√ß√£o, e 100 threads para a leitura da fila e grava√ß√£o no banco de dados em chunks de 2000 registros por vez.
- Consulta do total de registros para clientes e atendimentos nas rotas `/v1/customers/total` e `/v1/services/total`, facilitando o monitoramento da conclus√£o da carga batch.
- Consulta da rota `/v1/customers` com filtros para todos os campos (`email`, `nome` e `telefone`) e pagina√ß√£o a partir dos parameters `limit` e `offset`
- Consulta da rota `/v1/services` com filtros para todos os campos (`email`, `nome` e `telefone`) e pagina√ß√£o a partir dos parameters `limit` e `offset`
- Consuta da rota `/v1/indicators/productivity`, `/v1/indicators/sla/angel` e `/v1/indicators/sla/polo` com filtros de data (`start_date=YYYY-MM-DD` e `end_date=YYYY-MM-DD`) e ordena√ß√£o (`sort_field=<total, total_sla, avg_time>`  e `desc=<true, false>`)
- Monitoramento das requisi√ß√µes atrav√©s de logs com status e tempo de resposta, implementado a partir de um midlleware que calcula os tempos a cada requisi√ß√£o
![image](https://github.com/user-attachments/assets/769979f7-85a0-4cb2-a918-fa6b7542945b)
- Monitoramento do tempo de carga do arquivo batch atrav√©s dos logs
- Testes unit√°rios para os usecases que cont√©m o core das regras de neg√≥cios
- Testes end-to-end foram feitos a partir de uma collection do postman
- Padroniza√ß√£o de commits para cada tipo de altera√ß√£o (feat, refactor, test, build, doc) 
- Execu√ß√£o do projeto a partir do docker compose
- Build e push da imagem para o docker hub atrav√©s da pipeline do github actions
- Deploy da aplica√ß√£o na AWS ECS a partir da pipeline do CloudFormation
- Aplica√ß√£o desenvolvida seguindo princ√≠pios da orienta√ß√£o a objetos utilizando uma metodologia baseada na Clean Archtecture onde foram separadas as camadas de infra, controllers e usecases seguindo o seguinte fluxo:
  ![image](https://github.com/user-attachments/assets/b01a460a-7b7a-4bd3-84f9-9bdfbf5807e0)

  
## üîß Pr√© requisitos t√©cnicos
- Containers Docker para a execu√ß√£o da API e do banco de dados.
- Python 3 com Flask para cria√ß√£o da API
- Banco de dados Postgresql
- Projeto entregue pelo github
- README com instru√ß√µes para instala√ß√£o e execu√ß√£o do projeto

## üöÄ Instala√ß√£o e Setup
Para a execu√ß√£o do projeto √© necessario que o [docker](https://docs.docker.com/engine/install/) e o [docker compose](https://docs.docker.com/compose/install/) estejam instalados

1. Clone o reposit√≥rio
```bash
git clone https://github.com/jocsakesley/logistics_indicators_api.git
cd logistics_indicators_api
```

2. Configure as vari√°veis de ambiente (opcional)
 ```
 Arquivo .env disponibilizado no reposit√≥rio apenas para desenvolvimento
 Para produ√ß√£o √© recomendado que as vari√°veis sejam setadas de forma segura
 Vari√°veis do arquivo .env:
 POSTGRES_PASSWORD=postgres
 POSTGRES_USER=jocsa
 POSTGRES_DB=logistics
 POSTGRES_HOST=db
 JWT_SECRET_KEY=my-secret
```
3. Inicialize o docker (pelo docker desktop ou pelo teminal)
   
4. Rode o docker-compose
```bash
docker-compose up -d
```
5. Verifique que os containers da aplica√ß√£o, db e adminer est√£o rodando
```bash
docker ps
```

## üìì Documenta√ß√£o da API

A documenta√ß√£o pode ser baixada a partir [desse link](https://github.com/jocsakesley/logistics_indicators_api/blob/main/docs/logistics-api.postman_collection.json)   e importada para um client http como o postman ou baixar a [especifica√ß√£o openapi nesse link](https://github.com/jocsakesley/logistics_indicators_api/blob/main/docs/openapi.yaml) e importar no editor online [swagger editor](https://editor.swagger.io/) para uma melhor visualiza√ß√£o.

<<<<<<< HEAD
## üíª Como usar

- Fa√ßa o upload do arquivo `bd_desafio.csv` na rota `/v1/customers/batch`
- Monitore o total de linhas inseridas na rota `/v1/customers/total` (o total deve ser 573670)
- Fa√ßa o upload do arquivo `customers_data.csv` na rota `/v1/services/batch`
- Monitore o total de linhas inseridas na rota `/v1/services/total` (o total deve ser 1048575)
- Registre um usu√°rio na rota `/v1/auth/register` com `username`, `email` e `password`
- Fa√ßa login na rota `/v1/auth/login` e copie o `access_token` retornado
- Fa√ßa as devidas consultas conforme a documenta√ß√£o, passando no header o key `Authorization` e no value `Bearer <access_token>` 
=======
Obs.: Para as consultas, √© poss√≠vel remover os filtros para trazer todos os resultados com pagina√ß√£o para clientes e atendimentos.
>>>>>>> 0985e0e (refactor: move files to docs e utils and update README.MD)

## üß™ Rodando Testes
Os testes podem ser executados a partir dos seguintes comandos:

```bash
pip install -r tests/requirements_tests.txt
coverage run -m pytest -s -v tests
coverage report
```

## üî• Desafios
Durante a execu√ß√£o do projeto me deparei com alguns desafios para o deploy via pipeline do github actions. As roles de acesso para meu usu√°rio do github estavam funcionando por√©m o setup de configura√ß√£o da m√°quina remota requeria alguns passos que poderiam ser facilmente contornados com uma imagem da instancia personalizada e consequentemente mais cara.
Dessa forma optei por fazer o build e push da imagem pelo github actions no docker hub e a partir dessa imagem e com as configura√ß√µes de credenciais configuradas localmente, consegui fazer o deploy no ECS usando docker contex para criar o cluster e os services a partir do docker-compose.prd.yml do projeto que inicializa uma pipeline do CloudFormation com todos os recursos necess√°rios para disponibiliza√ß√£o p√∫blica.

## üìù Oportunidades de melhoria
Para a evolu√ß√£o do projeto pude identificar alguns pontos de melhoria:
- Gerenciamento de usu√°rios (hoje s√≥ tem o registro)
- Corre√ß√£o para deploy inteiramente pelo github actions
- Revisar usecases que podem ser melhor divididos em outras partes
- Permitir configura√ß√£o de threads, chuncks e sleep times para o processamento de arquivo batch a partir de vari√°veis de ambiente, garantindo o melhor tradeoff para produ√ß√£o (O tempo de processamento atual no endere√ßo p√∫blico est√° maior que ao rodar localmente, devido a limita√ß√£o de configura√ß√£o para evitar custos)
- Montagem de um volume do banco de dados para garantir a persist√™ncia de arquivos ou uso do banco de dados gerenciado na nuvem (deixei sem volume para facilitar a remo√ß√£o dos dados da carga batch
- Aumentar a cobertura de testes para todo o projeto, bem como adicionar um job de testes na pipeline do github actions
- Adicionar documenta√ß√£o do swagger na aplica√ß√£o de forma autom√°tica


## üë§ Autor
- Jocs√£ Kesley - Backend Developer
- Email - jocsadm@gmail.com
- Project Link: https://github.com/username/project-name](https://github.com/jocsakesley/logistics_indicators_api

## üìä Status do projeto
- Development

